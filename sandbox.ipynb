{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_csv():\n",
    "    url = 'https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Proceed with saving the CSV data\n",
    "        pass\n",
    "    else:\n",
    "        # Print an error message or handle the failure appropriately\n",
    "        print(\"Error: Could not retrieve CSV data\")\n",
    "        exit()\n",
    "    filename = 'restaurant_inspection.csv'\n",
    "\n",
    "    # Save the CSV data to a file\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for line in response.iter_lines():\n",
    "            writer.writerow(line.decode('utf-8').split(','))\n",
    "    filename = 'restaurant_inspection.csv'\n",
    "    try:\n",
    "        df = pd.read_csv(filename, dtype={'ZIPCODE': str})\n",
    "    except pd.errors.ParserError:\n",
    "        df = pd.read_csv(filename, error_bad_lines=False, dtype={'ZIPCODE': str})\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import json\n",
    "import os\n",
    "\n",
    "ticker_data = yf.Ticker(\"NU\")\n",
    "\n",
    "ticker_data.fast_info.last_price\n",
    "ticker_data.news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_data.fast_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ticker_data = yf.Ticker(\"CIBR\")\n",
    "ticker_data.fast_info.quote_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_data = yf.Ticker(\"STNE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_data.cash_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr \n",
    "pdr.get_data_yahoo(['NU','STNE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key='329d9256a61624a75bbfa3a1def744ae'\n",
    "\n",
    "import financetoolkit as tool\n",
    "\n",
    "apple = tool.Toolkit(['AAPL'],api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple.get_balance_sheet_statement()\n",
    "\n",
    "\n",
    "ratios = apple.ratios.collect_all_ratios()\n",
    "ratios.columns = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "for id, row in ratios.iterrows():\n",
    "    print(id[1],row['2022'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(apple.get_historical_data()['Close'].tail(1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple.get_balance_sheet_statement().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple.get_income_statement().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewz = tool.Toolkit(['EWZ'],api_key=key)\n",
    "ewz.get_profile()\n",
    "ewz.get_historical_data()\n",
    "ewz.get_normalization_files()\n",
    "ewz.get_quote()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy = tool.Toolkit(['SPY'],api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy.get_historical_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion task submitted successfully\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Define a synthetic table\n",
    "data = [\n",
    "    {\"timestamp\": \"2023-08-12T00:00:00\", \"dimension1\": \"value1\", \"dimension2\": 10},\n",
    "    {\"timestamp\": \"2023-08-12T01:00:00\", \"dimension1\": \"value2\", \"dimension2\": 20},\n",
    "]\n",
    "with open('data.json', 'w') as f:\n",
    "    for row in data:\n",
    "        f.write(json.dumps(row) + '\\n')\n",
    "\n",
    "# Define the ingestion spec\n",
    "ingestion_spec = {\n",
    "    \"type\": \"index_parallel\",\n",
    "    \"spec\": {\n",
    "        \"dataSchema\": {\n",
    "            \"dataSource\": \"my_datasource\",\n",
    "            \"timestampSpec\": {\n",
    "                \"column\": \"timestamp\",\n",
    "                \"format\": \"auto\"\n",
    "            },\n",
    "            \"dimensionsSpec\": {\n",
    "                \"dimensions\": [\"dimension1\", \"dimension2\"]\n",
    "            },\n",
    "            \"metricsSpec\": [],\n",
    "            \"granularitySpec\": {\n",
    "                \"type\": \"uniform\",\n",
    "                \"segmentGranularity\": \"day\",\n",
    "                \"queryGranularity\": \"none\"\n",
    "            }\n",
    "        },\n",
    "        \"ioConfig\": {\n",
    "            \"type\": \"index_parallel\",\n",
    "            \"inputSource\": {\n",
    "                \"type\": \"local\",\n",
    "                \"baseDir\": \"/Users/aragaom/PersonalFinanceDashboard/\",\n",
    "                \"filter\": \"data.json\"\n",
    "            },\n",
    "            \"inputFormat\": {\n",
    "                \"type\": \"json\"\n",
    "            }\n",
    "        },\n",
    "        \"tuningConfig\": {\n",
    "            \"type\": \"index_parallel\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Druid Overlord URL (adjust the port if needed)\n",
    "overlord_url = \"http://localhost:8081/druid/indexer/v1/task\"\n",
    "\n",
    "# Send the ingestion spec to Druid\n",
    "response = requests.post(overlord_url, json=ingestion_spec)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Ingestion task submitted successfully\")\n",
    "else:\n",
    "    print(\"Failed to submit ingestion task\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
